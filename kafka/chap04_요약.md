# 요약

## 📌 리더와 팔로워의 개념
하나의 토픽 파티션에는 리더와 팔로워가 있음.

리더는 실제로 읽기/쓰기 연산을 처리하는 주체이며 팔로워는 리더의 데이터를 복제함.

클러스터 장애 발생 시 ISR(In-Sync Replica)에 속한 팔로워 중 하나가 새로운 리더로 승격됨.

그림 4-1은 프로듀서, 컨슈머, 리더/팔로워 관계를 시각적으로 보여줌.

## 📌 복제 유지와 커밋
리더와 팔로워는 ISR 그룹에 속해 안정성을 유지.

ISR에 포함되지 못한 팔로워는 리더 자격을 상실.

ISR의 동기화 상태를 통해 데이터 일관성과 무결성을 보장.

커밋(high water mark)은 모든 복제가 끝난 메시지까지의 위치를 나타냄.

컨슈머는 커밋된 메시지만 읽을 수 있음 → 메시지 불일치 방지.

## 📌 리더 선출 전/후 동작
장애로 리더가 교체되면 일부 팔로워가 리더로 승격됨.

리더 선출 이전에 읽은 메시지가 새 리더와 일치하지 않을 수 있음.

이를 통해 리더 장애 시 데이터 불일치 문제와 컨슈머 메시지 일관성 문제를 설명.

## 📌 단계별 리더-팔로워 리플리케이션 동작
리더가 메시지를 오프셋에 저장 → 팔로워는 리더에서 메시지를 가져와 저장.

그림 4-4 ~ 4-7: 메시지 저장 및 복제 과정을 오프셋과 함께 시각적으로 설명.

(그림 4-4) 리더가 message1 저장, 팔로워는 아직 미복제 상태.

(그림 4-5) 팔로워가 리더에서 message1 가져와 리플리케이션.

(그림 4-6) 리더가 새로운 message2 저장 → 팔로워는 fetch 요청으로 가져옴.

(그림 4-7) 모든 팔로워가 리더와 동일한 오프셋까지 커밋 완료.

ACK 통신 없이도 안정적인 리플리케이션 구조를 구현하여 리더 부하 최소화.

## 📌 리플리케이션 offset checkpoint
리더/팔로워는 replication-offset-checkpoint 파일에 마지막 커밋 위치를 기록.

이는 장애 복구 시 데이터를 어디까지 복제했는지 확인하는 역할.

## 📌 핵심 요약
Kafka는 리더와 팔로워 구조로 안정적인 데이터 처리와 복제를 보장.

ISR 그룹과 커밋 포인트를 통해 데이터 무결성과 컨슈머의 일관성을 유지.

리더 장애 시 팔로워가 신속히 리더로 승격되어 가용성을 높임.

ACK 통신을 최소화해 리더 부하를 줄이고 성능을 극대화.

## 📌 리더에포크(LeaderEpoch) 개념
리더에포크는 파티션의 리더가 바뀔 때마다 숫자가 1씩 증가함.

장애 복구 과정에서 메시지의 일관성을 유지하고, 리더와 팔로워 간 하이워터마크 충돌을 방지하기 위해 사용됨.

리더에포크가 없으면 복구 시 메시지 손실이나 중복 가능성 있음.

## 📌 장애 복구 과정 (리더에포크 미사용 예시)
팔로워가 리더에서 새 메시지를 복제하면서 하이워터마크를 올림.

장애로 팔로워가 복구되면 신뢰할 수 없는 메시지를 삭제하고 리더와 동기화.

리더에포크가 없으면 예상치 못한 장애 발생 시 일부 메시지가 영구 손실될 수 있음.

그림 4-10 ~ 4-15: 리더 장애/복구 시 하이워터마크 충돌로 데이터 불일치 사례 설명.

## 📌 장애 복구 과정 (리더에포크 사용 예시)
복구된 팔로워가 리더에 리더에포크 요청.

리더는 리더에포크에 맞춰 안전하게 복구할 수 있는 오프셋을 알려줌.

팔로워는 불필요한 삭제 없이 안전한 하이워터마크로 조정함.

그림 4-11 ~ 4-16: 리더에포크 사용 시 메시지 손실 방지 과정 시각화.

## 📌 실습 명령어와 로그 확인
cat /data/kafka-logs/.../leader-epoch-checkpoint로 현재 리더에포크 상태 확인.

리더가 교체될 때마다 리더에포크 값이 1씩 증가함.

리더에포크와 오프셋 커밋 관계를 실습으로 단계별 검증.

## 📌 컨트롤러(Controller)
카프카 클러스터의 브로커 중 하나가 컨트롤러 역할을 담당.

컨트롤러는 ISR(복제본 리스트)을 관리하며, 브로커 장애 시 새로운 리더를 선출.

ISR 리스트 정보는 안정적 저장소에 보관.

컨트롤러는 리더 정보 변경 시 주키퍼에 기록하고 다른 브로커에 전파.

## 📌 리더 선출 예시
브로커 장애 발생 시 리더 선출 과정이 단계별로 도식화됨 (그림 4-20, 4-21).

브로커 다운 → ISR 변화 감지.

컨트롤러가 새로운 리더 후보 선택.

주키퍼에 리더 정보 기록.

정보가 다른 브로커로 전파됨.

제어된 종료(Controlled Shutdown) : SIG_TERM 신호로 브로커 종료 → 컨트롤러가 선출 작업 수행 → 다운타임 최소화.

## 📌 로그 세그먼트(Log Segment)
토픽의 메시지(레코드)는 로그 세그먼트 파일에 저장됨.

.index: 오프셋과 위치 정보.

.log: 실제 메시지 데이터.

.timeindex: 메시지 타임스탬프.

기본 1GB로 롤링(rolling) 전략 적용 → 크기 초과 시 새 세그먼트 생성.

## 📌 로그 세그먼트 삭제/컴팩션
log.cleanup.policy 옵션으로 관리.

삭제(delete): 세그먼트 보관 주기(retention.ms) 만료 시 삭제.

컴팩션(compaction): 키 기반 최신 메시지 보존, 나머지 삭제.

retention.ms, retention.bytes 등으로 세그먼트 삭제 시점/크기 제어 가능.

실습 예시: retention.ms=0으로 변경하여 세그먼트 즉시 삭제 확인.

## 📌 주요 명령어 예시
sudo systemctl start kafka-server: 브로커 시작.

kafka-configs.sh --alter --delete-config retention.ms: retention.ms 옵션 삭제.

kafka-topics.sh --describe: 토픽 정보 확인.

## 📌 추가 설명
다운타임 최소화: 제어된 종료는 리더 선출 과정이 종료 전에 수행되어 복구 시간이 짧음.

자연스러운 종료: SIG_TERM 신호로 graceful shutdown.

컴팩션: 대표적으로 _consumer_offsets 토픽에 적용.

## 📌 로그 컴팩션 (Log Compaction)
개념: Kafka는 메시지 로그에서 오래된 메시지를 삭제하는 일반적인 retention 삭제와 달리, 컴팩션(compaction)은 메시지 키를 기준으로 가장 최신 상태만 유지하는 정책입니다.

대표 예: _consumer_offset 토픽.

소비자가 읽은 오프셋 정보는 키-밸류 형태로 저장됨.

불필요한 과거 메시지는 삭제하고 마지막 오프셋 정보만 유지해 디스크 효율성 ↑.

## 📌 컴팩션 동작 예시
그림 4-22는 로그 컴팩션 전후를 비교:

오프셋과 키, 밸류가 순서대로 기록됨.

동일한 키에 대해 마지막 메시지만 남기고 이전 값은 삭제됨.

예) K1 키에 대해 V4가 최신이면 V1, V2, V3는 제거.

## 📌 장점과 주의점
장점: 장애 복구 시 전체 로그를 복원하지 않고 키 기준으로 최신 상태만 복원 → 빠른 재처리.

주의: 모든 토픽에 무조건 적용하지 않음.

최종 상태만 필요한 워크로드에 적합.

활성화 시 디스크 I/O 부하 ↑ → 리소스 모니터링 필수.

## 📌 관련 설정 옵션 (표 4-2)
옵션 이름	설명
cleanup.policy	compact: 토픽 레벨에서 컴팩션 적용
log.cleanup.policy	compact: 브로커 설정 파일 단위 적용
log.cleaner.min.compaction.lag.ms	메시지 기록 후 컴팩션까지 최소 지연시간
log.cleaner.max.compaction.lag.ms	최대 지연시간 지정
log.cleaner.min.cleanable.ratio	디스크 상 dirty 비율이 최소 얼마 이상일 때 컴팩션 실행

## 📌 전체 정리
Kafka의 내부 동작은 리플리케이션, 리더 선출, 컨트롤러, 로그 세그먼트 롤링과 삭제, 컴팩션 등을 통해 신뢰성을 유지.

클러스터 장애가 발생해도 데이터 손실 없이 빠르고 안정적으로 복구.

운영자는 이런 원리를 이해하고 설정 옵션을 적절히 조정해야 한다는 점이 강조됨.
